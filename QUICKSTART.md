# ğŸš€ LMU Campus LLM - Quick Start Guide

Get your LMU Campus AI Assistant running in minutes!

## ğŸ¯ One-Command Setup

For the fastest setup, run our automated installer:

```bash
python start_campus_llm.py
```

This script will:
- âœ… Check your Python version
- âœ… Install Python dependencies
- âœ… Install and configure Ollama
- âœ… Download the LLaMA 3.2 model
- âœ… Set up the knowledge base
- âœ… Run tests
- âœ… Launch the application

## ğŸ“‹ Manual Setup (if needed)

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Install Ollama

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**macOS/Windows:**
- Visit [ollama.ai](https://ollama.ai)
- Download the installer for your system
- Run the installer

### 3. Start Ollama & Download Model

```bash
# Start Ollama service
ollama serve &

# Download LLaMA 3.2 model (this may take a while)
ollama pull llama3.2:3b
```

### 4. Initialize Knowledge Base

```bash
python scripts/setup_knowledge_base.py
```

### 5. Launch the Application

```bash
python app.py
```

## ğŸŒ Using the Application

1. **Open your browser** to `http://localhost:7860`
2. **Enter your student ID** (optional) to track points
3. **Ask questions** about LMU!

### Example Questions to Try:
- "Where can I find a math tutor?"
- "What's the GPA requirement for study abroad?"
- "What events are happening this week?"
- "How do I file an academic grievance?"
- "Where is the counseling center?"

## ğŸ† Points & Engagement System

Earn points by:
- **Asking questions**: 1 point
- **Attending events**: 5-10 points
- **Giving feedback**: 3 points

### Point Levels:
- ğŸ¦ **Young Lion**: 0-19 points
- ğŸ¥‰ **Bronze Lion**: 20-49 points
- ğŸ¥ˆ **Silver Lion**: 50-99 points
- ğŸ¥‡ **Gold Lion**: 100-199 points
- ğŸ‘‘ **Legendary Lion**: 200+ points

## ğŸ‰ Managing Events

### View Current Events
```bash
python scripts/update_events.py --list
```

### Add New Event
```bash
python scripts/update_events.py --add
```

### Generate Sample Events
```bash
python scripts/update_events.py --sample
```

## ğŸ”§ Troubleshooting

### "Ollama not found" Error
```bash
# Check if Ollama is installed
ollama --version

# If not, install it:
curl -fsSL https://ollama.ai/install.sh | sh
```

### "Model not available" Error
```bash
# Download the model
ollama pull llama3.2:3b

# Check available models
ollama list
```

### "Service not running" Error
```bash
# Start Ollama service
ollama serve

# Check if it's running (in another terminal)
curl http://localhost:11434/api/tags
```

### Python Dependencies Issues
```bash
# Create virtual environment (recommended)
python -m venv campus_llm_env
source campus_llm_env/bin/activate  # Linux/macOS
# campus_llm_env\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

## ğŸ§ª Testing

### Quick Test
```bash
python tests/test_basic_functionality.py --quick
```

### Full Test Suite
```bash
python tests/test_basic_functionality.py --full
```

## ğŸ“ Project Structure

```
campus-llm/
â”œâ”€â”€ app.py                 # Main Gradio application
â”œâ”€â”€ start_campus_llm.py    # One-command setup
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ src/                   # Core modules
â”‚   â”œâ”€â”€ llm_handler.py     # LLM interface
â”‚   â”œâ”€â”€ rag_system.py      # Knowledge retrieval
â”‚   â”œâ”€â”€ points_system.py   # Engagement tracking
â”‚   â””â”€â”€ data_collector.py  # Data gathering
â”œâ”€â”€ data/                  # Knowledge and user data
â”œâ”€â”€ scripts/               # Utility scripts
â””â”€â”€ tests/                 # Test files
```

## ğŸ’¡ Tips for Success

1. **Start with sample data**: Use `--sample` flag to populate events
2. **Customize knowledge**: Add your own LMU information to `data/lmu_knowledge/`
3. **Monitor usage**: Check `data/logs/` for user interactions
4. **Engage students**: Promote the points system and rewards
5. **Keep events updated**: Regular updates keep students engaged

## ğŸ¤ Getting Help

### Common Issues:
- **Slow responses**: Normal for first run (model loading)
- **Memory usage**: LLaMA 3.2 3B needs ~4GB RAM
- **Port conflicts**: Change port in `config.json` if 7860 is busy

### Support Resources:
- Check the logs in `campus_llm.log`
- Review the test results
- Verify your Python version (3.8+ required)

## ğŸ“ Next Steps

1. **Deploy to cloud**: Consider AWS, GCP, or Azure for broader access
2. **Integrate with LMU systems**: Connect to PROWL, LionsConnect
3. **Add more data sources**: Scrape additional LMU websites
4. **Implement QR codes**: For event check-ins
5. **Build mobile app**: React Native or Flutter frontend

---

**Built with â¤ï¸ by Vanessa Akaraiwe for the LMU community**

ğŸ¦ *Let's bring LMU back to life!* ğŸ¦